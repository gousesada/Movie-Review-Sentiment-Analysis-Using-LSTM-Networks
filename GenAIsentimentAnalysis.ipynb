{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcvGFt64HNfss4rpS4MN0Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gousesada/Movie-Review-Sentiment-Analysis-Using-LSTM-Networks/blob/main/GenAIsentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "KPs3AQbvyRa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data (assuming you have a CSV file with 'text' and 'sentiment' columns)\n",
        "data = pd.read_csv('/content/IMDB Dataset.csv')\n",
        "texts = data['review'].values\n",
        "labels = data['sentiment'].values"
      ],
      "metadata": {
        "id": "ypqukZ0TyVYD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = data['review'].values,data['sentiment'].values\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y)\n",
        "print(f'shape of train data is {x_train.shape}')\n",
        "print(f'shape of test data is {x_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLnYYttAMzUB",
        "outputId": "11d87f55-66cc-42cf-8905-b9593573cc7c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of train data is (37500,)\n",
            "shape of test data is (12500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jilq2XwGNQTc",
        "outputId": "cd0110bc-2b23-4b17-ad68-75733b909d45"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example function to tokenize the dataset\n",
        "def tokenize(x_train, y_train, x_test, y_test):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokenize()"
      ],
      "metadata": {
        "id": "ZH7ZtK7uNX8y"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "le, labels"
      ],
      "metadata": {
        "id": "m0nZZc47ygzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "628a2ba7-9d1c-40cf-ce22-e7e0b7c3ed8e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(LabelEncoder(), array([1, 1, 1, ..., 0, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Pw1-RjEoykpi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text\n",
        "max_words = 10000\n",
        "max_len = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)"
      ],
      "metadata": {
        "id": "ug1SU9nHyphp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = Sequential([\n",
        "    Embedding(max_words, 128, input_length=max_len),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    LSTM(32),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "h0rZOoAXypo_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f996d6-7c67-4b85-80c9-0e1726e99ff3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "early_stopping"
      ],
      "metadata": {
        "id": "zMyvSzDSyprq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55481f33-3e95-4566-a76b-06ad6968ce59"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.early_stopping.EarlyStopping at 0x79869bed26e0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "vrRWtvtvyput",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61302530-89cb-43ce-f8e2-10a7b75dda7b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 152ms/step - accuracy: 0.7334 - loss: 0.5121 - val_accuracy: 0.8614 - val_loss: 0.3229\n",
            "Epoch 2/10\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 143ms/step - accuracy: 0.8985 - loss: 0.2620 - val_accuracy: 0.8724 - val_loss: 0.3077\n",
            "Epoch 3/10\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 137ms/step - accuracy: 0.9352 - loss: 0.1767 - val_accuracy: 0.8604 - val_loss: 0.3636\n",
            "Epoch 4/10\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 134ms/step - accuracy: 0.9610 - loss: 0.1150 - val_accuracy: 0.8614 - val_loss: 0.4572\n",
            "Epoch 5/10\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 136ms/step - accuracy: 0.9733 - loss: 0.0844 - val_accuracy: 0.8484 - val_loss: 0.4858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "IKHQn2a8y4b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a70c9465-7a34-49f1-f16f-371b769c40aa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.8727 - loss: 0.3029\n",
            "Test Loss: 0.3049\n",
            "Test Accuracy: 0.8710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict sentiment\n",
        "def predict_sentiment(text):\n",
        "    sequence = tokenizer.texts_to_sequences([text])\n",
        "    padded = pad_sequences(sequence, maxlen=max_len)\n",
        "    prediction = model.predict(padded)[0][0]\n",
        "    print(prediction)\n",
        "    return \"Positive\" if prediction > 0.7 else \"Negative\"\n"
      ],
      "metadata": {
        "id": "k_zo1XD-y4fC"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "example_text = \"i'm unhappy!\"\n",
        "print(f\"Sentiment: {predict_sentiment(example_text)}\")"
      ],
      "metadata": {
        "id": "amPDR7DAzCBI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22d34884-a15e-409d-d1fe-34f4f9f35190"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "0.56337774\n",
            "Sentiment: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "inYnkfpY8xG5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}